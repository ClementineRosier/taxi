{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import random\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crs = {'init': 'epsg:4326'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    POINT (-73.99465215457163 40.73519616365903)\n",
       "1    POINT (-73.99706966379965 40.73546280987431)\n",
       "2    POINT (-74.00681944352681 40.72344185905749)\n",
       "3    POINT (-73.79439300079635 40.73944287003665)\n",
       "4    POINT (-73.84872054010768 40.72137188695677)\n",
       "Name: geometry, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## college & universities\n",
    "# load data\n",
    "college = 'C:/Users/cleme/Documents/ENSAE/2A/S1/Python/Projet/Donnees/original_collegeanduniversity.shp'\n",
    "df_college = gpd.read_file(college).to_crs(crs)\n",
    "#build column based of the geo points\n",
    "col_college = gpd.GeoSeries(df_college.geometry)\n",
    "col_college.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## health facilities\n",
    "#load data\n",
    "hospital = 'C:/Users/cleme/Documents/ENSAE/2A/S1/Python/Projet/Donnees/original_hospitals.csv'\n",
    "df_hospital = pd.read_csv(hospital, sep=\";\")\n",
    "#extract long and lat from location 1 column in the df \n",
    "df_hospital['position'] = df_hospital['Location 1'].str.replace(r'[^(]*\\(|\\)[^)]*', '')\n",
    "df_hospital['newlongitude'] = df_hospital['position'].str.replace(r'[^,]*\\,', '')\n",
    "df_hospital['newlatitude']= df_hospital['position'].str.replace(r'\\,[^,]*', '')\n",
    "#convert them as a float and then as geo points to build the specific column\n",
    "df_hospital['newlatitude'] = df_hospital['newlatitude'].astype(float)\n",
    "df_hospital['newlongitude'] = df_hospital['newlongitude'].astype(float)\n",
    "df_hospital['geometry'] = gpd.GeoSeries([Point(xy) for xy in zip(df_hospital.newlongitude, df_hospital.newlatitude)])\n",
    "geodf_hospital = gpd.GeoDataFrame(df_hospital,crs=crs)\n",
    "geodf_hospital = geodf_hospital.set_geometry(\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "##Points of Interest\n",
    "#load data\n",
    "PoI = 'C:/Users/cleme/Documents/ENSAE/2A/S1/Python/Projet/Donnees/original_PointOfInterest.shp'\n",
    "df_PoI = gpd.read_file(PoI).to_crs(crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #recensement des abréviations\n",
    "ab_religion = pd.Series(['religion','CATHEDRAL','SYNAGOGUE','EPISCOPAL', 'TEMPLE', 'CHUR','TMPL','TABERNACLE',' CH ', 'CATHDL', 'CHAPEL','CONGREGAT','CONGEGRATION', 'EVANGICAL LUTH','ISRAEL'])\n",
    "ab_consulate = pd.Series(['consulate','CONSULATE'])\n",
    "ab_park= pd.Series(['park','PARK','PLGD','PLAYGROUND', 'PLAYGRND', 'RECREATION', 'SQUARE', 'GARDEN'])\n",
    "ab_theatre = pd.Series(['theatre','THEATRE', 'THTR'])\n",
    "ab_school = pd.Series(['school','HS','HIGH SCHOOL', 'SCHL', ' SC ','SCHOOL','ACADEMY'])\n",
    "ab_library = pd.Series(['library','LIBRARY'])\n",
    "ab_daycare = pd.Series(['daycare','DAY CARE','DAYCARE','NURSERY','NURSING','NURSIG'])\n",
    "ab_cemetery = pd.Series (['cemetry','CEMETERY','CMTRY'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#on vire les nan de la colonne name car impossible de les catégoriser\n",
    "df_PoI=df_PoI.dropna(subset=['name'])\n",
    "df_PoI.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Création des dummy variables\n",
    "j=0\n",
    "df_PoI['dum_religion']=0\n",
    "df_PoI['dum_consulate']=0\n",
    "df_PoI['dum_park']=0\n",
    "df_PoI['dum_theatre']=0\n",
    "df_PoI['dum_school']=0\n",
    "df_PoI['dum_library']=0\n",
    "df_PoI['dum_daycare']=0\n",
    "df_PoI['dum_cemetery']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sortie de la boucle\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#we create dummy variables to classify the points of interest\n",
    "\n",
    "\n",
    "while j < (df_PoI.shape[0] - 1) :\n",
    "    i=0\n",
    "    while ( i < ab_religion.size and df_PoI.loc[j,'dum_religion']==0 ):\n",
    "            if ab_religion.loc[i] in df_PoI.loc[j,'name']:\n",
    "                df_PoI.set_value(j,'dum_religion', 1)\n",
    " #         print('On recherche ', i,' dans ', j, '. Limit is ', ab_religion.size)\n",
    "            i+=1    \n",
    "     \n",
    "    i=0\n",
    "    while ( i < ab_consulate.size and df_PoI.loc[j,'dum_consulate']==0 and df_PoI.loc[j,'dum_religion']==0 ):\n",
    "            if ab_consulate.loc[i] in df_PoI.loc[j,'name']:\n",
    "                df_PoI.set_value(j,'dum_consulate', 1)\n",
    "#          print('On recherche ', i,' dans ', j, '. Limit is ', ab_consulate.size)\n",
    "            i+=1           \n",
    "          \n",
    "    i=0 \n",
    "    while ( i < ab_park.size and df_PoI.loc[j,'dum_park']==0and df_PoI.loc[j,'dum_consulate']==0  and df_PoI.loc[j,'dum_religion']==0 ):\n",
    "            if ab_park.loc[i] in df_PoI.loc[j,'name']:\n",
    "                df_PoI.set_value(j,'dum_park', 1)\n",
    " #         print('On recherche ', i,' dans ', j, '. Limit is ', ab_park.size)\n",
    "            i+=1\n",
    "    \n",
    "    i=0 \n",
    "    while ( i < ab_theatre.size and df_PoI.loc[j,'dum_theatre']==0 and df_PoI.loc[j,'dum_park']==0 and df_PoI.loc[j,'dum_consulate']==0 and df_PoI.loc[j,'dum_religion']==0 ):\n",
    "          if ab_theatre.loc[i] in df_PoI.loc[j,'name']:\n",
    "                df_PoI.set_value(j,'dum_theatre', 1)\n",
    "#          print('On recherche ', i,' dans ', j, '. Limit is ', ab_theatre.size)\n",
    "          i+=1\n",
    "          \n",
    "    i=0\n",
    "    while ( i < ab_school.size and df_PoI.loc[j,'dum_school']==0 and df_PoI.loc[j,'dum_theatre']==0and df_PoI.loc[j,'dum_park']==0 and df_PoI.loc[j,'dum_consulate']==0 and df_PoI.loc[j,'dum_religion']==0 ):\n",
    "          if ab_school.loc[i] in df_PoI.loc[j,'name']:\n",
    "                df_PoI.set_value(j,'dum_school', 1)\n",
    "#          print('On recherche ', i,' dans ', j, '. Limit is ', ab_school.size)\n",
    "          i+=1\n",
    "\n",
    "\n",
    "    i=0 \n",
    "    while ( i < ab_library.size and df_PoI.loc[j,'dum_library']==0 and df_PoI.loc[j,'dum_school']==0 and df_PoI.loc[j,'dum_theatre']==0and df_PoI.loc[j,'dum_park']==0and df_PoI.loc[j,'dum_consulate']==0 and df_PoI.loc[j,'dum_religion']==0 ):\n",
    "          if ab_library.loc[i] in df_PoI.loc[j,'name']:\n",
    "                df_PoI.set_value(j,'dum_library', 1)\n",
    "#          print('On recherche ', i,' dans ', j, '. Limit is ', ab_library.size)\n",
    "          i+=1\n",
    "          \n",
    "    i=0 \n",
    "    while ( i < ab_daycare.size and df_PoI.loc[j,'dum_daycare']==0 and df_PoI.loc[j,'dum_library']==0 and df_PoI.loc[j,'dum_school']==0 and df_PoI.loc[j,'dum_theatre']==0 and df_PoI.loc[j,'dum_park']==0 and df_PoI.loc[j,'dum_consulate']==0 and df_PoI.loc[j,'dum_religion']==0 ):\n",
    "        if ab_daycare.loc[i] in df_PoI.loc[j,'name']:\n",
    "            df_PoI.set_value(j,'dum_daycare', 1)\n",
    "#          print('On recherche ', i,' dans ', j, '. Limit is ', ab_daycare.size)\n",
    "        i+=1          \n",
    "          \n",
    "          \n",
    "    i=0 \n",
    "    while ( i < ab_cemetery.size and df_PoI.loc[j,'dum_cemetery']==0 and df_PoI.loc[j,'dum_daycare']==0 and df_PoI.loc[j,'dum_library']==0 and df_PoI.loc[j,'dum_school']==0 and df_PoI.loc[j,'dum_theatre']==0and df_PoI.loc[j,'dum_park']==0and df_PoI.loc[j,'dum_consulate']==0 and df_PoI.loc[j,'dum_religion']==0 ):\n",
    "        if ab_cemetery.loc[i] in df_PoI.loc[j,'name']:\n",
    "            df_PoI.set_value(j,'dum_cemetery', 1)\n",
    "#          print('On recherche ', i,' dans ', j, '. Limit is ', ab_cemetery.size)\n",
    "        i+=1          \n",
    "          \n",
    "    j+=1\n",
    "     \n",
    "print(\"sortie de la boucle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    POINT (-73.93634786975662 40.68091615244033)\n",
       "1    POINT (-73.93569488141881 40.75255340482011)\n",
       "2    POINT (-73.91828483362288 40.65080302570205)\n",
       "3    POINT (-74.00674292455398 40.62742678200225)\n",
       "4    POINT (-73.94597769590463 40.80647201947438)\n",
       "Name: geometry, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lieux de culte\n",
    "df_religion=df_PoI[df_PoI.dum_religion!=0]\n",
    "df_religion.reset_index(drop=True, inplace=True)\n",
    "col_religion = gpd.GeoSeries(df_religion.geometry)\n",
    "col_religion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#consulate\n",
    "df_consulate=df_PoI[df_PoI.dum_consulate!=0]\n",
    "df_consulate.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#park\n",
    "df_park=df_PoI[df_PoI.dum_park!=0]\n",
    "df_park.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#theatre\n",
    "df_theatre=df_PoI[df_PoI.dum_theatre!=0]\n",
    "df_theatre.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#school\n",
    "df_school=df_PoI[df_PoI.dum_school!=0]\n",
    "df_school.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#library\n",
    "df_library=df_PoI[df_PoI.dum_library!=0]\n",
    "df_library.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#daycare\n",
    "df_daycare=df_PoI[df_PoI.dum_daycare!=0]\n",
    "df_daycare.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cemetery\n",
    "df_cemetery=df_PoI[df_PoI.dum_cemetery!=0]\n",
    "df_cemetery.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on utilise la base de données des taxi dispo sur le site de NYC\n",
    "data = 'C:/Users/cleme/Documents/ENSAE/2A/S1/Python/Projet/Donnees/yellow_tripdata_2016-06.csv'\n",
    "\n",
    "# !!! on prend un échantillon de 100 observations pour commencer\n",
    "df = pd.read_csv(data, sep=',')\n",
    "df.head()\n",
    "\n",
    "#on ne garde que les courses payées en carte bleue pour avoir celles où le pourboire apparait\n",
    "df = df[df.payment_type==1]\n",
    "df = df[(df['pickup_longitude'] < -73.7) & (df['pickup_longitude'] > -74.1) & (df['pickup_latitude'] > 40.4) & (df['pickup_latitude'] < 51)]\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>Id_course</th>\n",
       "      <th>pts</th>\n",
       "      <th>circles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4022580</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-17 09:18:39</td>\n",
       "      <td>2016-06-17 09:25:56</td>\n",
       "      <td>1</td>\n",
       "      <td>1.27</td>\n",
       "      <td>-73.982132</td>\n",
       "      <td>40.771759</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.36</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-73.98213195800781 40.77175903320313)</td>\n",
       "      <td>POLYGON ((-73.97713195800782 40.77175903320313...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46413</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-09 23:40:54</td>\n",
       "      <td>2016-06-09 23:56:33</td>\n",
       "      <td>1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>-73.994591</td>\n",
       "      <td>40.750271</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.75</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-73.99459075927734 40.75027084350585)</td>\n",
       "      <td>POLYGON ((-73.98959075927735 40.75027084350585...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6822078</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-20 08:39:35</td>\n",
       "      <td>2016-06-20 08:47:30</td>\n",
       "      <td>1</td>\n",
       "      <td>1.51</td>\n",
       "      <td>-74.014702</td>\n",
       "      <td>40.710003</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.96</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT (-74.01470184326173 40.71000289916992)</td>\n",
       "      <td>POLYGON ((-74.00970184326174 40.71000289916992...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7181837</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-21 19:16:55</td>\n",
       "      <td>2016-06-21 19:27:35</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>-73.985298</td>\n",
       "      <td>40.727509</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.75</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (-73.98529815673827 40.72750854492188)</td>\n",
       "      <td>POLYGON ((-73.98029815673827 40.72750854492188...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1303480</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-05 16:05:52</td>\n",
       "      <td>2016-06-05 16:20:07</td>\n",
       "      <td>5</td>\n",
       "      <td>2.63</td>\n",
       "      <td>-73.979683</td>\n",
       "      <td>40.760971</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.36</td>\n",
       "      <td>4</td>\n",
       "      <td>POINT (-73.97968292236328 40.76097106933594)</td>\n",
       "      <td>POLYGON ((-73.97468292236329 40.76097106933594...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "0  4022580         2  2016-06-17 09:18:39   2016-06-17 09:25:56   \n",
       "1    46413         1  2016-06-09 23:40:54   2016-06-09 23:56:33   \n",
       "2  6822078         2  2016-06-20 08:39:35   2016-06-20 08:47:30   \n",
       "3  7181837         1  2016-06-21 19:16:55   2016-06-21 19:27:35   \n",
       "4  1303480         2  2016-06-05 16:05:52   2016-06-05 16:20:07   \n",
       "\n",
       "   passenger_count  trip_distance  pickup_longitude  pickup_latitude  \\\n",
       "0                1           1.27        -73.982132        40.771759   \n",
       "1                1           3.20        -73.994591        40.750271   \n",
       "2                1           1.51        -74.014702        40.710003   \n",
       "3                1           2.40        -73.985298        40.727509   \n",
       "4                5           2.63        -73.979683        40.760971   \n",
       "\n",
       "   RatecodeID store_and_fwd_flag  \\\n",
       "0           1                  N   \n",
       "1           1                  N   \n",
       "2           1                  N   \n",
       "3           1                  N   \n",
       "4           1                  N   \n",
       "\n",
       "                         ...                          fare_amount  extra  \\\n",
       "0                        ...                                  7.0    0.0   \n",
       "1                        ...                                 13.5    0.5   \n",
       "2                        ...                                  7.5    0.0   \n",
       "3                        ...                                 10.0    1.0   \n",
       "4                        ...                                 12.0    0.0   \n",
       "\n",
       "   mta_tax  tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0      0.5        1.56           0.0                    0.3          9.36   \n",
       "1      0.5        2.95           0.0                    0.3         17.75   \n",
       "2      0.5        1.66           0.0                    0.3          9.96   \n",
       "3      0.5        2.95           0.0                    0.3         14.75   \n",
       "4      0.5        2.56           0.0                    0.3         15.36   \n",
       "\n",
       "   Id_course                                           pts  \\\n",
       "0          0  POINT (-73.98213195800781 40.77175903320313)   \n",
       "1          1  POINT (-73.99459075927734 40.75027084350585)   \n",
       "2          2  POINT (-74.01470184326173 40.71000289916992)   \n",
       "3          3  POINT (-73.98529815673827 40.72750854492188)   \n",
       "4          4  POINT (-73.97968292236328 40.76097106933594)   \n",
       "\n",
       "                                             circles  \n",
       "0  POLYGON ((-73.97713195800782 40.77175903320313...  \n",
       "1  POLYGON ((-73.98959075927735 40.75027084350585...  \n",
       "2  POLYGON ((-74.00970184326174 40.71000289916992...  \n",
       "3  POLYGON ((-73.98029815673827 40.72750854492188...  \n",
       "4  POLYGON ((-73.97468292236329 40.76097106933594...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(35)\n",
    "# assez lent, !!! on crée df0 = les 100 premières obs de la grosse base\n",
    "df0 = df.sample(100).reset_index()\n",
    "#on crée un identifiant unique par course\n",
    "df0['Id_course']= df0.index\n",
    "df0.head()\n",
    "df0['pts'] = gpd.GeoSeries([Point(xy) for xy in zip(df0.pickup_longitude, df0.pickup_latitude)])\n",
    "df0['circles'] = gpd.GeoSeries(df0.pts).buffer(0.005)\n",
    "df0=gpd.GeoDataFrame(df0).set_geometry('circles', crs = crs)\n",
    "\n",
    "df0.head()\n",
    "\n",
    "# le problème c'est qu'on a quelques valeurs très éloignées de la zone, il faut absolument les supprimer\n",
    "# si on ne les supprime pas (essayer avec les 100 premières obs), le plot (les boroughs de NYC) et le subplot\n",
    "# (les cercles qu'on a dessiné) ne sont plus tout à la même échelle\n",
    "# = > on sélectionne les observations dont les pickup coordinates ne sortent pas de la zone de NYC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'pickup_longitude',\n",
       "       'pickup_latitude', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'dropoff_longitude', 'dropoff_latitude', 'payment_type', 'fare_amount',\n",
       "       'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
       "       'improvement_surcharge', 'total_amount', 'Id_course', 'pts', 'circles',\n",
       "       'nb_college', 'nb_hospital', 'nb_religion', 'nb_consulate', 'nb_park',\n",
       "       'nb_theatre', 'nb_school', 'nb_library', 'nb_daycare', 'nb_cemetery'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# college\n",
    "nb_coll_circle = gpd.sjoin(df_college, df0.copy(),op='within')\n",
    "count_coll = nb_coll_circle.groupby('Id_course').size()\n",
    "count_coll.name=\"nb_college\"\n",
    "\n",
    "#hospitals\n",
    "nb_hosp_circle = gpd.sjoin(geodf_hospital, df0.copy(),op='within')\n",
    "count_hosp = nb_hosp_circle.groupby('Id_course').size()\n",
    "count_hosp.name=\"nb_hospital\"\n",
    "\n",
    "\n",
    "#religion\n",
    "nb_rel_circle = gpd.sjoin(df_religion, df0.copy(),op='within')\n",
    "count_rel = nb_rel_circle.groupby('Id_course').size()\n",
    "count_rel.name=\"nb_religion\"\n",
    "\n",
    "#consulate\n",
    "nb_cons_circle = gpd.sjoin(df_consulate, df0.copy(),op='within')\n",
    "count_cons = nb_cons_circle.groupby('Id_course').size()\n",
    "count_cons.name=\"nb_consulate\"\n",
    "\n",
    "#park\n",
    "nb_park_circle = gpd.sjoin(df_park, df0.copy(),op='within')\n",
    "count_park = nb_park_circle.groupby('Id_course').size()\n",
    "count_park.name=\"nb_park\"\n",
    "\n",
    "#theatre\n",
    "nb_th_circle = gpd.sjoin(df_theatre, df0.copy(),op='within')\n",
    "count_th = nb_th_circle.groupby('Id_course').size()\n",
    "count_th.name=\"nb_theatre\"\n",
    "\n",
    "#school\n",
    "nb_sc_circle = gpd.sjoin(df_school, df0.copy(),op='within')\n",
    "count_sc = nb_sc_circle.groupby('Id_course').size()\n",
    "count_sc.name=\"nb_school\"\n",
    "\n",
    "#library\n",
    "nb_lib_circle = gpd.sjoin(df_library, df0.copy(),op='within')\n",
    "count_lib = nb_lib_circle.groupby('Id_course').size()\n",
    "count_lib.name=\"nb_library\"\n",
    "\n",
    "#daycare\n",
    "nb_dc_circle = gpd.sjoin(df_daycare, df0.copy(),op='within')\n",
    "count_dc = nb_dc_circle.groupby('Id_course').size()\n",
    "count_dc.name=\"nb_daycare\"\n",
    "\n",
    "#cemetery\n",
    "nb_cem_circle = gpd.sjoin(df_cemetery, df0.copy(),op='within')\n",
    "count_cem = nb_cem_circle.groupby('Id_course').size()\n",
    "count_cem.name=\"nb_cemetery\"\n",
    "\n",
    "\n",
    "df0_count = pd.concat([df0, count_coll,count_hosp,count_rel,count_cons,count_park,count_th,count_sc,count_lib ,count_dc,count_cem], axis=1)\n",
    "df0_count[['nb_college','nb_hospital','nb_religion','nb_consulate','nb_park','nb_theatre','nb_school','nb_library','nb_daycare','nb_cemetery']]=df0_count[['nb_college','nb_hospital','nb_religion','nb_consulate','nb_park','nb_theatre','nb_school','nb_library','nb_daycare','nb_cemetery']].fillna(0)\n",
    "\n",
    "df0_count.head()\n",
    "df0_count.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On commence la régression !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passenger_count', 'trip_distance', 'fare_amount', 'extra',\n",
       "       'nb_college', 'nb_hospital', 'nb_religion', 'nb_consulate', 'nb_park',\n",
       "       'nb_theatre', 'nb_school', 'nb_library', 'nb_daycare', 'nb_cemetery'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on divise en train et en test\n",
    "f=df0_count.columns.get_loc(\"passenger_count\")\n",
    "i=df0_count.columns.get_loc(\"payment_type\")\n",
    "j=df0_count.columns.get_loc(\"extra\")\n",
    "k=df0_count.columns.get_loc(\"nb_college\")\n",
    "\n",
    "l=list(range(f,f+2))+list(range (i+1,j+1))+list(range(k,df0_count.shape[1]))\n",
    "\n",
    "X, y = df0_count[df0_count.columns[l]], df0_count['tip_amount']\n",
    "\n",
    "# On peut utiliser random_state=42 (par exemple) en option pour ne pas dependre du seed\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [-0.16643366  0.0223585   0.10754155  1.07296331 -0.58471087  0.35527052\n",
      " -0.02253912 -0.01892997 -0.00589602  0.00596273  0.12693219  0.42599131\n",
      " -0.38104716 -0.58936733]\n",
      "Mean squared error: 4.61\n",
      "Variance score: 0.56\n"
     ]
    }
   ],
   "source": [
    "# On emprunte le code sur le site de scikit-learn et on l'adapte a notre probleme\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
